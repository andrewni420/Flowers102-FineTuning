## Fine Tuning CNNs on the Oxford Flowers Dataset

This notebook demonstrates how to fine tune resnet50 convolutional neural networks on the Oxford Flowers dataset. The dataset has large variations in light, scale, and pose, and only has 8K examples. 
This makes it difficult to learn the trends in the dataset without pretraining or data augmentation.

In this notebook, we fine-tune a resnet50 model from the [original paper](https://arxiv.org/abs/1512.03385) pretrained on ImageNet1k. We use the [TrivialAugment](https://openaccess.thecvf.com/content/ICCV2021/papers/Muller_TrivialAugment_Tuning-Free_Yet_State-of-the-Art_Data_Augmentation_ICCV_2021_paper.pdf)
data augmentation method to improve our model's generalization, and achieve a test accuracy of 96.0%. 

# My solution process

My first step in approaching this problem was to get a prototype working. By following online tutorials, I downloaded the model and datasets, and wrote a training loop to fine-tune the model on the flowers dataset. After a few epochs, this model reached a decent accuracy of around 80%. While following the tutorial, I learned about different ways to fine-tune models, such as freezing the base model weights and only training the final layer, or training the entire model together. Since training was not taking too long with a GPU, I decided to train the entire model at once. 

My next step was to improve the performance of this prototype. By looking at the dataset description and reading some review papers on image classification and fine-tuning, I discovered that the Oxford Flowers dataset had large variations in its images, which made it difficult for models to learn the dataset. To combat this, I decided to use data augmentation to artificially increase the number of examples in the training set. After trying some state-of-the-art data augmentation methods like AutoAugment, as well as some custom data augmentation pipelines like crop + rotate + photometric distortion, I found that TrivialAugment had the best performance on the validation set. Another common way of improving generalization is through regularization methods like weight decay. The papers I found did not use weight decay for fine-tuning, and I found that it did not improve the validation performance, so I did not use weight decay.

After optimizing the data augmentation, the next logical step was to optimize the SGD algorithm. From the papers I read, it seemed that SGD with momentum was the norm in image classification. However, I also tried the Adam algorithm and its variant AMSGrad, and found that AMSGrad had the best performance on the validation set. At the same time, I also optimized the learning rate, finding that a learning rate of 0.0005 with a cosine decay schedule worked best. Finally, I trained the optimized model on both the training and validation sets, and evaluated it on the testing set to get an accuracy of 96%.

However, in comparison the state-of-the-art results on the Oxford Flowers dataset reach as high an accuracy as 99.76%. Although these accuracies were achieved by transformer models, I found a few papers using resnet models, including [one paper](https://arxiv.org/pdf/2106.00116v4.pdf) achieving 98.2% accuracy using a resnet50 model. The key difference was that they pretrained on the much larger ImageNet21k dataset. Therefore, to obtain better results, I turned to broader pretraining and used the resnet50 model from [Big Transfer (BiT): General Visual Representation Learning](https://arxiv.org/pdf/1912.11370.pdf). From the validation error, I found that their model did not really continue improving after 30 or so epochs, so to reduce the computational requirement I cut the fine-tuning short there. In addition, since 30 epochs is small compared to the time scale of their learning rate annealing, I simply kept the initial learning rate constant. Validation error showed that this was the right decision, as attempting to use a learning rate schedule resulted in the model performing worse. To combat the variations in light in the Flowers dataset, I also added brightness randomizations to their default random cropping data augmentation. After fine-tuning, this optimized model achieves 98.2% accuracy, a significant improvement over my previous result.
